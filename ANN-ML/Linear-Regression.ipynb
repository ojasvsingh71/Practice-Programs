{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8e7b488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OJASV\\.cache\\kagglehub\\datasets\\tushardobal\\india-city-air-quality-index-dataset-20152023\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"tushardobal/india-city-air-quality-index-dataset-20152023\")\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b77748ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OJASV\\.cache\\kagglehub\\datasets\\tushardobal\\india-city-air-quality-index-dataset-20152023\\versions\\1\\india_city_aqi_2015_2023.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "csv_path=os.path.join(path,\"india_city_aqi_2015_2023.csv\")\n",
    "print(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef3bec8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            city        date        pm25        pm10        no2        so2  \\\n",
      "0          Delhi  2015-01-01   99.868566  147.103280  49.715328  19.615149   \n",
      "1          Delhi  2015-01-02  143.168513  208.517207  32.957884  14.712800   \n",
      "2          Delhi  2015-01-03   89.678491  101.412886  14.126233   9.188562   \n",
      "3          Delhi  2015-01-04   43.679037   65.432963  61.984732  10.871118   \n",
      "4          Delhi  2015-01-05   58.224691  110.443143  22.735096  13.878490   \n",
      "...          ...         ...         ...         ...        ...        ...   \n",
      "32865  Ahmedabad  2023-12-27  104.189767  125.996540  54.037235   9.458740   \n",
      "32866  Ahmedabad  2023-12-28   78.296822  126.139390  21.102546  14.506215   \n",
      "32867  Ahmedabad  2023-12-29  133.796319  174.428556  14.262469   9.569303   \n",
      "32868  Ahmedabad  2023-12-30   34.293435   67.092247  43.458757  13.238309   \n",
      "32869  Ahmedabad  2023-12-31   52.469690   82.606862  27.533347   7.257668   \n",
      "\n",
      "             co         o3  aqi  aqi_category  \n",
      "0      0.729754  46.487946  103      Moderate  \n",
      "1      0.660975  43.014054  141      Moderate  \n",
      "2      0.496151  54.713710   82  Satisfactory  \n",
      "3      0.820258  28.628777   50          Good  \n",
      "4      0.619808  45.624594   69  Satisfactory  \n",
      "...         ...        ...  ...           ...  \n",
      "32865  1.214473  69.390920  102      Moderate  \n",
      "32866  0.383592  45.033878   83  Satisfactory  \n",
      "32867  1.058658  65.074983  127      Moderate  \n",
      "32868  0.805538  27.954360   44          Good  \n",
      "32869  0.636559  63.218900   60  Satisfactory  \n",
      "\n",
      "[32870 rows x 10 columns]\n",
      "\n",
      "Index(['city', 'date', 'pm25', 'pm10', 'no2', 'so2', 'co', 'o3', 'aqi',\n",
      "       'aqi_category'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(csv_path)\n",
    "print(df)\n",
    "\n",
    "print()\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19d69ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pm25', 'pm10', 'no2', 'so2', 'co', 'o3', 'aqi', 'aqi_category'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Removed the unwanted column\n",
    "df=df.drop(\"date\",axis=1)\n",
    "df=df.drop(\"city\",axis=1)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8902558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target and feature seperation\n",
    "y=df[\"aqi_category\"]\n",
    "X=df.drop(\"aqi_category\",axis=1)\n",
    "\n",
    "# Filling missing values\n",
    "X=pd.get_dummies(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5bc0b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             pm25        pm10        no2        so2        co         o3  aqi\n",
      "0       99.868566  147.103280  49.715328  19.615149  0.729754  46.487946  103\n",
      "1      143.168513  208.517207  32.957884  14.712800  0.660975  43.014054  141\n",
      "2       89.678491  101.412886  14.126233   9.188562  0.496151  54.713710   82\n",
      "3       43.679037   65.432963  61.984732  10.871118  0.820258  28.628777   50\n",
      "4       58.224691  110.443143  22.735096  13.878490  0.619808  45.624594   69\n",
      "...           ...         ...        ...        ...       ...        ...  ...\n",
      "32865  104.189767  125.996540  54.037235   9.458740  1.214473  69.390920  102\n",
      "32866   78.296822  126.139390  21.102546  14.506215  0.383592  45.033878   83\n",
      "32867  133.796319  174.428556  14.262469   9.569303  1.058658  65.074983  127\n",
      "32868   34.293435   67.092247  43.458757  13.238309  0.805538  27.954360   44\n",
      "32869   52.469690   82.606862  27.533347   7.257668  0.636559  63.218900   60\n",
      "\n",
      "[32870 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scaling numeric values\n",
    "scaler=StandardScaler()\n",
    "\n",
    "X_scaled=scaler.fit_transform(X)\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc00bfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded=le.fit_transform(y)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_scaled,y_encoded,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f469102e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OJASV\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m260\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">772</span> (3.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m772\u001b[0m (3.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">772</span> (3.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m772\u001b[0m (3.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Sequential name=sequential_4, built=True>\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(len(le.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f3e2ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9146 - loss: 0.3452 - val_accuracy: 0.9648 - val_loss: 0.1398\n",
      "Epoch 2/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9747 - loss: 0.1145 - val_accuracy: 0.9844 - val_loss: 0.0824\n",
      "Epoch 3/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9852 - loss: 0.0810 - val_accuracy: 0.9926 - val_loss: 0.0620\n",
      "Epoch 4/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9896 - loss: 0.0655 - val_accuracy: 0.9909 - val_loss: 0.0525\n",
      "Epoch 5/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0544 - val_accuracy: 0.9916 - val_loss: 0.0448\n",
      "Epoch 6/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9921 - loss: 0.0468 - val_accuracy: 0.9928 - val_loss: 0.0411\n",
      "Epoch 7/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0410 - val_accuracy: 0.9947 - val_loss: 0.0349\n",
      "Epoch 8/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9935 - loss: 0.0366 - val_accuracy: 0.9941 - val_loss: 0.0322\n",
      "Epoch 9/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0332 - val_accuracy: 0.9922 - val_loss: 0.0304\n",
      "Epoch 10/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9945 - loss: 0.0309 - val_accuracy: 0.9962 - val_loss: 0.0273\n",
      "Epoch 11/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9949 - loss: 0.0285 - val_accuracy: 0.9937 - val_loss: 0.0263\n",
      "Epoch 12/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0270 - val_accuracy: 0.9970 - val_loss: 0.0244\n",
      "Epoch 13/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9951 - loss: 0.0256 - val_accuracy: 0.9968 - val_loss: 0.0221\n",
      "Epoch 14/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9950 - loss: 0.0243 - val_accuracy: 0.9968 - val_loss: 0.0241\n",
      "Epoch 15/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9958 - loss: 0.0231 - val_accuracy: 0.9977 - val_loss: 0.0205\n",
      "Epoch 16/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9958 - loss: 0.0224 - val_accuracy: 0.9973 - val_loss: 0.0199\n",
      "Epoch 17/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9958 - loss: 0.0208 - val_accuracy: 0.9962 - val_loss: 0.0188\n",
      "Epoch 18/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0201 - val_accuracy: 0.9933 - val_loss: 0.0213\n",
      "Epoch 19/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0194 - val_accuracy: 0.9926 - val_loss: 0.0202\n",
      "Epoch 20/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9954 - loss: 0.0196 - val_accuracy: 0.9949 - val_loss: 0.0194\n",
      "Epoch 21/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9969 - loss: 0.0183 - val_accuracy: 0.9983 - val_loss: 0.0159\n",
      "Epoch 22/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9966 - loss: 0.0177 - val_accuracy: 0.9977 - val_loss: 0.0168\n",
      "Epoch 23/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9967 - loss: 0.0173 - val_accuracy: 0.9954 - val_loss: 0.0178\n",
      "Epoch 24/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0167 - val_accuracy: 0.9973 - val_loss: 0.0152\n",
      "Epoch 25/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9973 - loss: 0.0162 - val_accuracy: 0.9979 - val_loss: 0.0152\n",
      "Epoch 26/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9969 - loss: 0.0158 - val_accuracy: 0.9951 - val_loss: 0.0156\n",
      "Epoch 27/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0156 - val_accuracy: 0.9979 - val_loss: 0.0141\n",
      "Epoch 28/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0151 - val_accuracy: 0.9947 - val_loss: 0.0153\n",
      "Epoch 29/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9972 - loss: 0.0144 - val_accuracy: 0.9971 - val_loss: 0.0141\n",
      "Epoch 30/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9973 - loss: 0.0144 - val_accuracy: 0.9960 - val_loss: 0.0143\n",
      "Epoch 31/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0143 - val_accuracy: 0.9983 - val_loss: 0.0130\n",
      "Epoch 32/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9971 - loss: 0.0135 - val_accuracy: 0.9970 - val_loss: 0.0130\n",
      "Epoch 33/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0139 - val_accuracy: 0.9985 - val_loss: 0.0132\n",
      "Epoch 34/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9976 - loss: 0.0126 - val_accuracy: 0.9941 - val_loss: 0.0144\n",
      "Epoch 35/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9974 - loss: 0.0126 - val_accuracy: 0.9975 - val_loss: 0.0118\n",
      "Epoch 36/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0129 - val_accuracy: 0.9979 - val_loss: 0.0121\n",
      "Epoch 37/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9975 - loss: 0.0121 - val_accuracy: 0.9973 - val_loss: 0.0118\n",
      "Epoch 38/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0122 - val_accuracy: 0.9983 - val_loss: 0.0107\n",
      "Epoch 39/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9975 - loss: 0.0117 - val_accuracy: 0.9987 - val_loss: 0.0105\n",
      "Epoch 40/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0114 - val_accuracy: 0.9977 - val_loss: 0.0108\n",
      "Epoch 41/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0110 - val_accuracy: 0.9949 - val_loss: 0.0135\n",
      "Epoch 42/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9973 - loss: 0.0115 - val_accuracy: 0.9975 - val_loss: 0.0109\n",
      "Epoch 43/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9978 - loss: 0.0110 - val_accuracy: 0.9987 - val_loss: 0.0109\n",
      "Epoch 44/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0106 - val_accuracy: 0.9916 - val_loss: 0.0175\n",
      "Epoch 45/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 0.0106 - val_accuracy: 0.9979 - val_loss: 0.0102\n",
      "Epoch 46/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9971 - loss: 0.0109 - val_accuracy: 0.9989 - val_loss: 0.0091\n",
      "Epoch 47/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0098 - val_accuracy: 0.9949 - val_loss: 0.0116\n",
      "Epoch 48/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0098 - val_accuracy: 0.9987 - val_loss: 0.0091\n",
      "Epoch 49/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0099 - val_accuracy: 0.9964 - val_loss: 0.0117\n",
      "Epoch 50/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9973 - loss: 0.0100 - val_accuracy: 0.9970 - val_loss: 0.0101\n",
      "Epoch 51/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0095 - val_accuracy: 0.9977 - val_loss: 0.0096\n",
      "Epoch 52/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 0.0090 - val_accuracy: 0.9987 - val_loss: 0.0088\n",
      "Epoch 53/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0090 - val_accuracy: 0.9987 - val_loss: 0.0084\n",
      "Epoch 54/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 0.0090 - val_accuracy: 0.9971 - val_loss: 0.0097\n",
      "Epoch 55/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0091 - val_accuracy: 0.9990 - val_loss: 0.0081\n",
      "Epoch 56/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0089 - val_accuracy: 0.9973 - val_loss: 0.0093\n",
      "Epoch 57/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 0.0084 - val_accuracy: 0.9990 - val_loss: 0.0082\n",
      "Epoch 58/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0081 - val_accuracy: 0.9989 - val_loss: 0.0081\n",
      "Epoch 59/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 0.0082 - val_accuracy: 0.9987 - val_loss: 0.0075\n",
      "Epoch 60/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9973 - loss: 0.0088 - val_accuracy: 0.9975 - val_loss: 0.0083\n",
      "Epoch 61/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 0.0082 - val_accuracy: 0.9989 - val_loss: 0.0090\n",
      "Epoch 62/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0076 - val_accuracy: 0.9937 - val_loss: 0.0135\n",
      "Epoch 63/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9983 - loss: 0.0077 - val_accuracy: 0.9975 - val_loss: 0.0118\n",
      "Epoch 64/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0077 - val_accuracy: 0.9990 - val_loss: 0.0074\n",
      "Epoch 65/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9981 - loss: 0.0081 - val_accuracy: 0.9981 - val_loss: 0.0076\n",
      "Epoch 66/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0071 - val_accuracy: 0.9979 - val_loss: 0.0083\n",
      "Epoch 67/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0074 - val_accuracy: 0.9979 - val_loss: 0.0073\n",
      "Epoch 68/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0075 - val_accuracy: 0.9977 - val_loss: 0.0086\n",
      "Epoch 69/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0075 - val_accuracy: 0.9979 - val_loss: 0.0096\n",
      "Epoch 70/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9984 - loss: 0.0070 - val_accuracy: 0.9979 - val_loss: 0.0075\n",
      "Epoch 71/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0070 - val_accuracy: 0.9947 - val_loss: 0.0106\n",
      "Epoch 72/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9984 - loss: 0.0070 - val_accuracy: 0.9985 - val_loss: 0.0083\n",
      "Epoch 73/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0067 - val_accuracy: 0.9981 - val_loss: 0.0076\n",
      "Epoch 74/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0066 - val_accuracy: 0.9962 - val_loss: 0.0087\n",
      "Epoch 75/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0070 - val_accuracy: 0.9985 - val_loss: 0.0069\n",
      "Epoch 76/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0064 - val_accuracy: 0.9977 - val_loss: 0.0075\n",
      "Epoch 77/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0063 - val_accuracy: 0.9977 - val_loss: 0.0072\n",
      "Epoch 78/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0065 - val_accuracy: 0.9964 - val_loss: 0.0084\n",
      "Epoch 79/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0062 - val_accuracy: 0.9981 - val_loss: 0.0077\n",
      "Epoch 80/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 0.0061 - val_accuracy: 0.9966 - val_loss: 0.0083\n",
      "Epoch 81/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9983 - loss: 0.0059 - val_accuracy: 0.9981 - val_loss: 0.0083\n",
      "Epoch 82/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0065 - val_accuracy: 0.9987 - val_loss: 0.0065\n",
      "Epoch 83/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0064 - val_accuracy: 0.9977 - val_loss: 0.0094\n",
      "Epoch 84/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9983 - loss: 0.0061 - val_accuracy: 0.9977 - val_loss: 0.0070\n",
      "Epoch 85/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0057 - val_accuracy: 0.9990 - val_loss: 0.0066\n",
      "Epoch 86/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0062 - val_accuracy: 0.9994 - val_loss: 0.0054\n",
      "Epoch 87/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0055 - val_accuracy: 0.9964 - val_loss: 0.0074\n",
      "Epoch 88/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9981 - loss: 0.0064 - val_accuracy: 0.9960 - val_loss: 0.0076\n",
      "Epoch 89/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9985 - loss: 0.0057 - val_accuracy: 0.9992 - val_loss: 0.0057\n",
      "Epoch 90/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0054 - val_accuracy: 0.9979 - val_loss: 0.0064\n",
      "Epoch 91/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9977 - loss: 0.0065 - val_accuracy: 0.9943 - val_loss: 0.0135\n",
      "Epoch 92/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0060 - val_accuracy: 0.9964 - val_loss: 0.0085\n",
      "Epoch 93/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0050 - val_accuracy: 0.9971 - val_loss: 0.0084\n",
      "Epoch 94/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0055 - val_accuracy: 0.9983 - val_loss: 0.0058\n",
      "Epoch 95/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9984 - loss: 0.0057 - val_accuracy: 0.9979 - val_loss: 0.0062\n",
      "Epoch 96/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0053 - val_accuracy: 0.9943 - val_loss: 0.0103\n",
      "Epoch 97/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0047 - val_accuracy: 0.9962 - val_loss: 0.0080\n",
      "Epoch 98/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0053 - val_accuracy: 0.9975 - val_loss: 0.0073\n",
      "Epoch 99/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9986 - loss: 0.0052 - val_accuracy: 0.9975 - val_loss: 0.0085\n",
      "Epoch 100/100\n",
      "\u001b[1m658/658\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0052 - val_accuracy: 0.9958 - val_loss: 0.0079\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6f7d72c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0078\n",
      "\n",
      "Test Accuracy: 0.9958928823471069\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"\\nTest Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6604e281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "       Predicted        Actual\n",
      "0       Moderate      Moderate\n",
      "1   Satisfactory  Satisfactory\n",
      "2           Good          Good\n",
      "3       Moderate      Moderate\n",
      "4   Satisfactory  Satisfactory\n",
      "5   Satisfactory  Satisfactory\n",
      "6   Satisfactory  Satisfactory\n",
      "7   Satisfactory  Satisfactory\n",
      "8       Moderate      Moderate\n",
      "9           Good          Good\n",
      "10  Satisfactory  Satisfactory\n",
      "11      Moderate      Moderate\n",
      "12      Moderate      Moderate\n",
      "13      Moderate      Moderate\n",
      "14  Satisfactory  Satisfactory\n",
      "15          Good          Good\n",
      "16  Satisfactory  Satisfactory\n",
      "17      Moderate      Moderate\n",
      "18  Satisfactory  Satisfactory\n",
      "19  Satisfactory  Satisfactory\n",
      "\n",
      "Total correct: 6547 / 6574\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compare predictions vs actual\n",
    "pred = model.predict(X_test)\n",
    "pred_classes = np.argmax(pred, axis=1)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison = pd.DataFrame({\n",
    "    'Predicted': le.inverse_transform(pred_classes),\n",
    "    'Actual': le.inverse_transform(y_test)\n",
    "})\n",
    "\n",
    "print(comparison.head(20))\n",
    "print(f\"\\nTotal correct: {(comparison['Predicted'] == comparison['Actual']).sum()} / {len(comparison)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
